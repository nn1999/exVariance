# vim: syntax=python tabstop=4 expandtab
# coding: utf-8

#---------------------------
# @author: Shang Zhang
# @email: shang_zhang@foxmail.com
# @date: Sep, 3rd, 2020
#---------------------------

include: '../common.snakemake'

bin_dir=config.get('bin_dir')
root_dir=config.get("root_dir")

output_dir=config.get('output_dir')
summary_dir=config.get('summary_dir')

count_method=config.get('count_method')
remove_duplicates_long=config.get('remove_duplicates_long')

## mapping step
if config.get('remove_duplicates_long'):
    map_steps = ['rRNA', 'genome', 'circRNA', 'rRNA_rmdup', 'genome_rmdup', 'circRNA_rmdup']
else:
    map_steps = ['genome', 'rRNA', 'circRNA']

## normalization step
config['normalization_methods'] = ["TMM", "RLE", "CPM", "CPM_top"]
config['batch_removal_methods'] = ["null", "RUV", "RUVn"]
# if has_batch_info:
#     config['batch_removal_methods'] += ['ComBat', 'limma']
config['imputation_methods'] = ['null']

# diff. exp. step
with open(config.get('data_dir') + '/compare_groups.yaml', 'r') as f:
    compare_groups = yaml.load(f, Loader=yaml.FullLoader)

def get_all_inputs(wildcards):

    # mapping_long_pe.snakemake
    available_inputs = dict(
        # mapping long pe # output section
        fastq_file=expand('{output_dir}/unmapped/{sample_id}/clean_{mate_index}.fastq.gz',output_dir=output_dir, sample_id=sample_ids, mate_index=[1,2]),
        bam=expand('{output_dir}/bam/{sample_id}/{map_step}.bam',output_dir=output_dir, sample_id=sample_ids, map_step=map_steps),
        map_paired_sorted_by_name=expand('{output_dir}/bam_sorted_by_name/{sample_id}/{map_step}.bam',output_dir=output_dir, sample_id=sample_ids, map_step=map_steps),
        # rmdup_bam=expand('{output_dir}/bam/{sample_id}/{map_step}_rmdup.bam',output_dir=output_dir, sample_id=sample_ids, map_step=map_steps),
        # mapping long pe # summary section
        count_clean_reads           =expand('{summary_dir}/fastq_clean_count/count_clean_reads/{sample_id}',summary_dir=summary_dir,sample_id=sample_ids),
        count_clean_fragments       =expand('{summary_dir}/fastq_clean_count/count_clean_fragments/{sample_id}/clean',summary_dir=summary_dir,sample_id=sample_ids),
        samtools_stats              =expand('{summary_dir}/all_bam_stats/{sample_id}/samtools_stats/{map_step}.txt',summary_dir=summary_dir,sample_id=sample_ids,map_step=map_steps),
        fragment_counts             =expand('{summary_dir}/all_bam_stats/{sample_id}/fragment_counts/{map_step}',summary_dir=summary_dir,sample_id=sample_ids,map_step=map_steps),
        insert_size_average         =expand('{summary_dir}/all_bam_stats/{sample_id}/insert_size_average/{map_step}',summary_dir=summary_dir,sample_id=sample_ids,map_step=map_steps),
        insert_size_hist            =expand('{summary_dir}/all_bam_stats/{sample_id}/insert_size_hist/{map_step}',summary_dir=summary_dir,sample_id=sample_ids,map_step=map_steps),
        read_length_hist            =expand('{summary_dir}/all_bam_stats/{sample_id}/read_length_hist/{map_step}',summary_dir=summary_dir,sample_id=sample_ids,map_step=map_steps),
        mapped_read_length_by_sample=expand('{summary_dir}/all_bam_stats/mapped_read_length_by_sample/{sample_id}',summary_dir=summary_dir,sample_id=sample_ids),
        mapped_insert_size_by_sample=expand('{summary_dir}/all_bam_stats/mapped_insert_size_by_sample/{sample_id}',summary_dir=summary_dir,sample_id=sample_ids),
        mapping_stat                =expand('{summary_dir}/all_bam_stats/mapping_stat.txt',summary_dir=summary_dir),
    )

    # bigwig_long.snakemake
    for map_step in map_steps:
        if map_step.startswith('genome'):
            strands = ['+', '-']
        else:
            strands = '+'
        available_inputs[map_step]                  = expand('{output_dir}/bigwig/{sample_id}.{map_step}.{strand}.bigWig',output_dir=output_dir, sample_id=sample_ids, map_step=map_step, strand=strands)
        available_inputs[map_step + '_normalized']  = expand('{output_dir}/bigwig_normalized/{sample_id}.{map_step}.{strand}.bigWig',output_dir=output_dir, sample_id=sample_ids, map_step=map_step, strand=strands)
        available_inputs[map_step + '_bam']         = expand('{output_dir}/bam_sorted_by_coord/{sample_id}/{map_step}.bam',output_dir=output_dir, sample_id=sample_ids, map_step=map_step)
        available_inputs[map_step + '_bai']         = expand('{output_dir}/bam_sorted_by_coord/{sample_id}/{map_step}.bam.bai',output_dir=output_dir, sample_id=sample_ids, map_step=map_step)
        if map_step.startswith('circRNA'):
            available_inputs[map_step + '_bigwig_pseudo_genome'] = expand('{output_dir}/bigwig_pseudo_genome/{sample_id}.{map_step}.{strand}.bigWig', output_dir=output_dir, sample_id=sample_ids, map_step=map_step, strand=strands)
            available_inputs[map_step + '_bam_pseudo_genome'] = expand('{output_dir}/bam_pseudo_genome/{sample_id}/{map_step}.bam', output_dir=output_dir, sample_id=sample_ids, map_step=map_step)
    
    enabled_inputs = list(available_inputs.keys())
    inputs = []
    for key, l in available_inputs.items():
        if key in enabled_inputs:
            inputs += l
            

    # normalization.snakemake
    for batch_removal_method in config['batch_removal_methods']:
        inputs.extend(expand('{output_dir}/matrix_processing/filter.{imputation_method}.Norm_{normalization_method}.Batch_{batch_removal_method}_{batch_index}.{count_method}.txt',
            output_dir=config.get('output_dir'),
            imputation_method=config['imputation_methods'],
            normalization_method=config['normalization_methods'],
            batch_removal_method=batch_removal_method,
            batch_index=config.get('batch_index'),
            count_method=config.get('count_method')))
        inputs.extend(expand('{output_dir}/matrix_processing/filter.{count_method}.txt',
            output_dir=config.get('output_dir'),
            count_method=config.get('count_method')))
    
    # # differential_expression.snakemake
    # inputs.extend(expand('{output_dir}/differential_expression/{count_method}/{compare_group}/{diffexp_method}.txt', output_dir=output_dir, count_method=config.get('count_method'), compare_group=compare_groups, diffexp_method=config.get('diffexp_method')))
    # inputs.extend(expand('{output_dir}/count_matrix/{count_method}.txt',output_dir=output_dir, count_method=config.get('count_method')))
    # inputs.extend(expand('{output_dir}/summary/read_counts.txt',output_dir=output_dir, sample_id=sample_ids))

    return inputs

# include: './diff_exp/differential_expression.snakemake'

    # if has_batch_info:
    #     inputs += expand('{output_dir}/differential_expression_with_batch/{batch_index}/{count_method}/{compare_group}/{diffexp_method}.txt',
    #             output_dir=config.get('output_dir'), batch_index=config['batch_index'], count_method=config['count_method'], compare_group=compare_groups, diffexp_method=config['diffexp_method'])

rule all:
    input:
        get_all_inputs
        

include: './diff_exp/mapping_long_pe.snakemake'
include: './diff_exp/bigwig_long.snakemake'
include: './diff_exp/count_matrix_long.snakemake'
include: './diff_exp/normalization.snakemake'